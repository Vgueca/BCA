\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{csvsimple}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{algorithm}
\makeatletter
\renewcommand{\ALG@name}{Algoritmo}
\makeatother
\usepackage{algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\newtheorem{theorem}{Teorema}[section]
\newtheorem{prop}{Proposición}[section]
\newtheorem{lema}{Lema}[section]
\newtheorem{col}{Colorario}[section]

\theoremstyle{definition}
\newtheorem{exmp}{Ejemplo}

\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]

\renewcommand*\contentsname{Índice} %Nombre del indice

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}



\begin{document}
\lstset{
	basicstyle=\footnotesize,
	extendedchars=true,
	literate={á}{{\'a}}1 {ã}{{\~a}}1 {é}{{\'e}}1 {ú}{{\'u}}1 {ó}{{\'o}}1,
	backgroundcolor=\color{black!5}
	}
	
\begin{titlepage}
	\centering
	{\includegraphics[scale=0.5]{Logo_UGR.png}\par}
	\vspace{1cm}
	{\bfseries\Large Science Faculty \par}
	\vspace{0.5cm}
	{\bfseries\itshape\large Multivariate Statics \par}
	\vspace{2.5cm}
	{\scshape\Huge Influence of diverse indicators in the diagnosis of breast cancer\par}
	\vspace{3cm}
	{\itshape\Large Bachelor's degree in Computer Science and Mathematics}
	\vfill
	{\Large Authors: \par}
	{\Large Julián Garrido Arana \par}
	{\Large Javier Gómez López \par}
	{\Large Juan Valentín Guerrero Cano \par}
	
	\vfill
	{\Large Course 2023-2024 \par}
\end{titlepage}

\thispagestyle{empty}
\null
\vfill

%%Información sobre la licencia
\parbox[t]{\textwidth}{
  \includegraphics[scale=0.05]{by-nc-sa.png}\\[4pt]
  \raggedright % Texto alineado a la izquierda
  \sffamily\large
  {\Large This work is distributed under a CC BY-NC-SA 4.0 license.}\\[4pt]
  You are free to distribute and adapt the material as long as you acknowledge\\
  the original authors of the document, do not use it for commercial purposes,\\
  and distribute it under the same license.\\[4pt]
  \texttt{creativecommons.org/licenses/by-nc-sa/4.0/}
}

\newpage

\tableofcontents

\newpage

\section{Abstract}
This study responds to the urgent need for a comprehensive understanding of factors influencing breast cancer diagnosis, a disease with substantial global health implications. Employing advanced statiscal techniques such as discriminant analysis, factorial analysis for dimensional reduction, and principal component analysis, the research aims to identify key indicators for more accurate breast cancer classification. \\

By improving diagnostic precision, the study contributes to early and personalized interventions. Additionaly, it seeks to unravel complex interrelationships among various indicators, offering potential insights for advancements in breast cancer research. In essence, this work addresses the practival imperative to enhance breast cancer diagnostics and contributes to ongoing efforts in understanding the intricate aspects of this disease, ultimately advancing medical knowledge and breast cancer treatment.

\newpage

\section{Introduction}
In the intricate realm of breast cancer, the quest for precise diagnosis demands a sophisticated analytical approach that transcends conventional methods. This study embarks on a meticulous exploration, leveraging advanced statistical techniques—discriminant analysis, dimensionality reduction through factorial analysis, and principal component analysis. Our focus centers on unraveling the intricate tapestry of morphological indicators within breast cancer datasets, specifically those linked to diverse sample forms across various cancers.

The amalgamation of genetic, clinical, and morphological indicators necessitates a nuanced statistical lens. Through discriminant analysis, we aim to unveil distinctive morphological patterns characterizing benign and malignant tumors, pushing the boundaries of traditional diagnostic methods. Simultaneously, the application of factorial and principal component analyses enables us to distill essential information from the complex dataset, shedding light on the mathematical factors that truly drive breast cancer classification.

This statistical exploration transcends immediate diagnostic applications. By identifying morphological indicators tied to diverse cancer samples, we not only enhance diagnostic precision but also contribute to a deeper mathematical understanding of the underlying relationships governing the manifestation of different forms of breast cancer. This statistical lens empowers us to navigate the complexities of the disease, unveiling hidden mathematical patterns and connections that may inform novel avenues of research.

In this journey, our objective is twofold: to refine breast cancer diagnosis by identifying morphological indicators associated with various cancer forms through advanced statistical analyses and to contribute to a broader mathematical understanding of the intricate relationships within the disease. As we dissect the statistical nuances associated with morphological variations, we envision a future where mathematical tools are not only more precise but also inherently adaptable to the diverse manifestations of breast cancer. Through this statistical lens, our exploration aspires to redefine the mathematical paradigm of breast cancer diagnosis, providing a foundation for more effective interventions and advancing the collective mathematical understanding of this complex and multifaceted disease.

This study aims to refine breast cancer diagnosis by identifying morphological indicators associated with various cancer forms through advanced statistical analyses, simultaneously contributing to a broader mathematical understanding of the intricate relationships within the disease.

\newpage

\section{Materials and Methods}
\subsection{Materials}

For this study, we have used a public Data Base published by the University of California, at its Machine Learning Repository. This database contains information about 30 `different' features measured through 569 instances of breast cancers. In fact, we do not have 30 features, we have 10, but because most of them refers to spatial measures, we have 3 for each one of this type (\(x,y,z\)). The ten real-valued feautres are computed for each cell nuclues:

\begin{itemize}
	\item Radius (mean of distances from center to points on the perimeter).
	\item Texture (standard deviation of gray-scale values).
	\item Perimeter.
	\item Area.
	\item Smoothness (local variation in radius lengths).
	\item Compactness (\(perimeter^2\) / \(area - 1.0\)).
	\item Concavity (severity of concave portions of the contour).
	\item Symmetry.
	\item Fractal dimension ("coastline approximation" - 1).
\end{itemize}

Due to the size of the features, we recommend to consult the \texttt{R} report of this work to see a summary of the principal position, dispersion and form measures of the features of the database. The table is at section 2.3, where we can find all this interest data.

\subsection{Statiscal methods}


\subsubsection{Univariate exploratory analysis}
First of all we have conducted an \textbf{univariate exploratory analysis}. Regarding the types of values we have on the dataset, we are not interested on perform any type of data-grouping.

We computed the porcentge of missing values, and we saw that there are not missing values. \\

Secondly, we went trough a classical numeric descriptive analysis where the basic numerical descriptive statistics such as principal position, dispersion and form measures were given. We also computed their histograms, boxplots and density graphs. \\

Thirdly, we tried to identify extreme values or outliers. Firstly, we standarized the data to avoid the different scales of our feautres. The decision took for the outliers were to substitute them with the median, due it works better than substituting with the mean. \\

Lastly, to avoid the assumption of normality, we checked the distribution of each feature of the dataset. We did it in a graphical way and using the Shapiro-Wilk test.

\subsubsection{Multivariate Exploratory Analysis}
First of all, we checked some conditions that are necessary to apply the different multivariate analysis techniques:

\begin{itemize}
	\item It is necessary to check if the variables are or no independent. At popultation level, we checked \textbf{correlation} using \textit{Bartlett's Test}.
	\item We also checked the multivariant normality, using the \textit{Henze-Zirkler} test and \textit{Royston} test. It is important to remark that these tests could be perturbated because the presence of outliers, so we had to eliminate them.
\end{itemize}

Once checked all this conditions, we had applied different techniques of Multivariant Analysis. We conducted a \textbf{Principal Component Analysis (PCA)} to reduce the dimension of the problem using observable  variables. After it, we made a \textbf{Factorial Analysis} to identify potential \textit{latent variables} (no observable) that have a high correlation with a group of observable variables and no correlation with the others. Lastly, we performed a \textbf{Discriminant Analysis} (\textbf{Linear} and \textbf{Quadratic}) to establish a classification method of new observations of a cualitative variable according to its characteristics (predictors).

\end{document}
